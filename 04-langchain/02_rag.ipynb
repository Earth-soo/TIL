{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf6d938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에 있는 환경변수들을 불러오기\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892abd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pypdf      # -q: 리스트 안 보여주고 조용히 설치\n",
    "# %pip install pypdf langchain-community\n",
    "# %pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5967d7",
   "metadata": {},
   "source": [
    "## 저장 파트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7935a2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sscbr\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "# 1. Document Load (PDF)\n",
    "# 지원하는 문서 로더: https://docs.langchain.com/oss/python/integrations/document_loaders\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 불러올 파일 위치\n",
    "file_path = './nke-10k-2023.pdf'\n",
    "#대상 pdf를 변환해줄 로더\n",
    "loader = PyPDFLoader(file_path)\n",
    "# 로더가 pdf를 python에서 쓸 수 있도록 변환(pdf 1page -> 1 Document)\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))    # 원본 pdf 페이지 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3430d318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516\n",
      "page_content='Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "(Mark One)\n",
      "☑ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "FOR THE FISCAL YEAR ENDED MAY 31, 2023\n",
      "OR\n",
      "☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "FOR THE TRANSITION PERIOD FROM                         TO                         .\n",
      "Commission File No. 1-10635\n",
      "NIKE, Inc.\n",
      "(Exact name of Registrant as specified in its charter)\n",
      "Oregon 93-0584541\n",
      "(State or other jurisdiction of incorporation) (IRS Employer Identification No.)\n",
      "One Bowerman Drive, Beaverton, Oregon 97005-6453\n",
      "(Address of principal executive offices and zip code)\n",
      "(503) 671-6453\n",
      "(Registrant's telephone number, including area code)\n",
      "SECURITIES REGISTERED PURSUANT TO SECTION 12(B) OF THE ACT:\n",
      "Class B Common Stock NKE New York Stock Exchange\n",
      "(Title of each class) (Trading symbol) (Name of each exchange on which registered)' metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': './nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "# 2. Splitting\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True    # add_start_index : 원본 문서 내에서 chunk 시작위치를 metadata에 포함할지 결정\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(chunks))   # 전체 chunk 개수\n",
    "print(chunks[0])   # 첫번째 청크의 원본 텍스트 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Embedding(숫자로 바꾸기)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 쪼개기\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# 아래는 테스트용(실제 텍스트 -> 벡터로 바뀌는 과정)\n",
    "v1 = embeddings.embed_query(chunks[0].page_content) # 청크1 벡터로 변환\n",
    "v2 = embeddings.embed_query(chunks[1].page_content) # 청크2 벡터로 변환\n",
    "\n",
    "# 차원수는 같아야 함\n",
    "print(len(v1) == len(v2))   # True(embedding 길이는 둘 다 동일한 모델을 사용했기 때문에 같음)\n",
    "print(v1[:10])  # 벡터 눈으로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde63837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Vector Store에 저장하기\n",
    "from langchain_core.vectorstores import InMemoryVectorStore     # memory에서만 실행하는 임시 vector storage\n",
    "\n",
    "# 테스트/개발용 메모리\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "# pdf 쪼개 놓은 chunks를 벡터스토어에 저장(저장 후 id 들이 나옴)\n",
    "ids = vector_store.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8111b8e",
   "metadata": {},
   "source": [
    "## 검색 파트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aadd(비동기식) vs add(기본)\n",
    "\n",
    "# 벡터스토어 -> 검색기 활용\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = 'similarity',         # 검색방식: 유사도\n",
    "    search_kwargs = { 'k':3 }             # 결과개수: 3개\n",
    ")\n",
    "\n",
    "# 검색\n",
    "retriever.invoke('나이키의 미국 영업점 개수는?')    # LangChain의 retriever 에서 내부적으로 질문을 임베딩 해줘서 따로 임베딩 안 해도 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c982a0",
   "metadata": {},
   "source": [
    "## Agent에 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c21dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기(retriever)를 Tool(함수)로 만들기\n",
    "from langchain.tools import tool    # decorator\n",
    "\n",
    "@tool   # LLM에게 \"이 함수는 네가 필요할 때 직접 호출해서 쓸 수 있는 도구야\" 라고 알려줌\n",
    "# 검색어(query)를 인자로 받음\n",
    "def search_vectorstore(query: str) -> str:\n",
    "    \"\"\"Retrieve info to help answer a query about Nike\"\"\"\n",
    "    # 검색기 대신 벡터스토어 바로 활용하기 (chunk 2개만 검색)\n",
    "    docs = vector_store.similarity_search(query, k=2)\n",
    "    result = ''\n",
    "\n",
    "    for doc in docs:\n",
    "        result += doc.page_content + '\\n\\n'\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "print(search_vectorstore('나이키 영업점 개수'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd59cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "# agent 안에 prompt를 다 쓰면 길어지기 때문에 변수로 빼기\n",
    "prompt = \"\"\"너는 2023 나이키 10k 보고서를 검색하는 도구를 다룰 수 있어. \n",
    "사용자 질문에 답변하기 위해 필요하면 사용해. 경제분석 전문가처럼 답변해.\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4.1-mini\",\n",
    "    tools=[search_vectorstore],\n",
    "    system_prompt=prompt\n",
    ")\n",
    "\n",
    "content = \"나이키 영업점 숫자와 각 영업점 평균 매출액이 궁금함.\"\n",
    "\n",
    "agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba257c",
   "metadata": {},
   "source": [
    "## Web 문서(HTML) RAG + Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e2ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 43047\n"
     ]
    }
   ],
   "source": [
    "# HTML은 문서 본문 외에 필요하지 않은 내용이 많음 -> 전처리 필요!\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 전처리\n",
    "bs4_strainer = bs4.SoupStrainer(class_=('post-title', 'post-header', 'post-content'))       # 해당 클래스만 뽑아옴\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    bs_kwargs={'parse_only': bs4_strainer}  # 처리기 넣기\n",
    "    # web_paths=[]      # 여러개의 웹 문서를 가져올 때\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "# 문서 페이지 수, 총 글자수\n",
    "print(len(docs), len(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5194dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, chunk_overlap = 200, add_start_index = True\n",
    ")\n",
    "\n",
    "pieces = splitter.split_documents(docs)\n",
    "# print(len(pieces))\n",
    "# print(pieces[0])\n",
    "\n",
    "# Embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "t_embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# Store\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "simple_vector = InMemoryVectorStore(t_embeddings)\n",
    "t_ids = simple_vector.add_documents(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7132e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LLM Agent는 어떤 방식으로 동작되는지 알려줘.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_simple_vecotr (call_noe3jQrqSV8Gxnxzp6boeA0w)\n",
      " Call ID: call_noe3jQrqSV8Gxnxzp6boeA0w\n",
      "  Args:\n",
      "    query: LLM Agent 동작 방식\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_simple_vecotr\n",
      "\n",
      "LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "}\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LLM Agent는 대규모 언어 모델(LLM)을 중심 제어기로 삼아 동작하는 시스템입니다. 주요 동작 방식은 다음과 같습니다.\n",
      "\n",
      "1. 계획 수립(Planning)\n",
      "   - 에이전트는 큰 작업을 더 작고 관리 가능한 하위 목표(subgoal)로 분해하여 복잡한 작업을 효율적으로 처리합니다.\n",
      "   - 스스로의 이전 행동에 대해 반성하고 비판(self-reflection and refinement)하여 실수를 학습하고 개선함으로써 결과의 품질을 높입니다.\n",
      "\n",
      "2. 메모리(Memory)\n",
      "   - 에이전트가 작업을 수행하면서 기억을 활용하여 정보를 축적하고 참조합니다.\n",
      "\n",
      "이와 같이 LLM Agent는 LLM을 '두뇌'로 하여 계획 수립, 자기 반성, 기억 등의 기능을 조합해 자율적으로 문제를 해결하는 방식으로 동작합니다. \n",
      "\n",
      "더 구체적인 내용이나 관련 예제가 필요하시면 알려주세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# 함수 생성\n",
    "@tool\n",
    "def search_simple_vecotr(query: str) -> str:\n",
    "    \"\"\"Retrieve info to help answer a query about LLM\"\"\"\n",
    "    # 검색기 대신 벡터스토어 바로 활용하기 (chunk 2개만 검색)\n",
    "    t_docs = simple_vector.similarity_search(query, k=2)\n",
    "    result = ''\n",
    "\n",
    "    for doc in t_docs:\n",
    "        result += doc.page_content + '\\n\\n'\n",
    "\n",
    "    return result\n",
    "\n",
    "# Agent에 통합하기\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "t_prompt='LLM Agent는 어떤 방식으로 동작되는지 알려줘.'\n",
    "\n",
    "t_agent = create_agent(\n",
    "    model='openai:gpt-4.1-mini',\n",
    "    tools=[search_simple_vecotr],\n",
    "    system_prompt=t_prompt\n",
    ")\n",
    "\n",
    "t_content='LLM Agent는 어떤 방식으로 동작되는지 알려줘.'\n",
    "\n",
    "# 에이전트가 *생각하고 도구를 사용하는 과정\"을 실시간으로 생중계 해줌\n",
    "for event in t_agent.stream({\"messages\": [{\"role\": \"user\", \"content\": t_content}]}, stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
